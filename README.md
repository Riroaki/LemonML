# ğŸ‹LemonğŸ‹

> **åŸºäºnumpyçš„åŸºæœ¬æœºå™¨å­¦ä¹ ç®—æ³•åº“**

æœ¬é¡¹ç›®èµ·æºäºZJU2019å¹´æ˜¥å¤å­¦æœŸçš„ã€Šæ•°æ®æŒ–æ˜å¯¼è®ºã€‹è¯¾ç¨‹ä½œä¸šã€‚

é¢„è®¡è¿‘æœŸå°†ä¼šåœ¨[ä¸ªäººåšå®¢](https://riroaki.github.io/)åŒæ­¥æ›´æ–°é¡¹ç›®ä¸­æ¶‰åŠçš„æœºå™¨å­¦ä¹ ç®—æ³•ç³»åˆ—å†…å®¹ã€‚

## ç›®æ ‡ï¼š

- æ¸…æ™°æ˜“æ‡‚çš„ä»£ç å’Œæ³¨é‡Š
- ç®€å•æ˜“ç”¨çš„API
- å…¨é¢çš„æœºå™¨å­¦ä¹ ç®—æ³•

## Structure

### æœ‰ç›‘ç£ç±»

- çº¿æ€§ç±»
  - çº¿æ€§å›å½’ï¼ˆåŸºäºæ¢¯åº¦/åŸºäºnormal equationï¼‰
  - é€»è¾‘å›å½’åˆ†ç±»
  - æ„ŸçŸ¥æœºåˆ†ç±»
  - SVMåˆ†ç±»
- éçº¿æ€§ç±»
  - è´å¶æ–¯åˆ†ç±»
  - kè¿‘é‚»åˆ†ç±»
  - å†³ç­–æ ‘åˆ†ç±»

### æ— ç›‘ç£ç±»

- K-Meansèšç±»
- Spectralèšç±»
- PCAä¸»æˆåˆ†åˆ†æ
- â€¦â€¦

### å·¥å…·å‡½æ•°

- batchæ‰¹é‡åˆ†å‰²
- scalingç¼©æ”¾ï¼ˆmin-max/mean/standardizatioin/unitï¼‰
- cross validationäº¤å‰éªŒè¯ï¼ˆK-fold/Leave-one-outï¼‰

## API

### SupervisedModel

- Class
  - `LinearRegression`
  - `LogisticRegression`
  - `Perceptron`
  - `SVM`
  - `KNearest`
  - `DecisionTree`
  - `...`
- Methods
  - `fit(x: np.ndarray, y: np.ndarray, **kwargs) -> np.ndarray`
  - `predict(x: np.ndarray, **kwargs) -> np.ndarray`
  - `evaluate(x: np.ndarray, y: np.ndarray, **kwargs) -> tuple`
  - `dump(dump_file: str) -> None`
  - `load(dump_file: str) -> None`

### UnsupervisedModel

- Class
  - `KMeans`
  - `Spectral`
  - `PCA`
  - `...`
- Methods
  - `Clustering(x: np.ndarray, **kwargs) -> np.ndarray`

### Utils

- `batch`
  - `batch(data: np.ndarray, y: np.ndarray, size: int, shuffle: bool = False) -> tuple`
- `cross_validate`
  - `k_fold(data: np.ndarray, y: np.ndarray, k: int, fit_func: callable, eval_func: callable, shuffle: bool = True) -> tuple`
  - `leave_one_out(data: np.ndarray, y: np.ndarray, fit_func: callable, eval_func: callable, shuffle: bool = True) -> tuple`
- `make_data`
  - `linear(n: int, dim: int, rand_bound: float = 10., noisy: bool = False) -> tuple`
  - `logistic(n: int, dim: int, rand_bound: float = 10., noisy: bool = False) -> tuple`
  - `perceptron(n: int, dim: int, rand_bound: float = 10., noisy: bool = False) -> tuple`
  - `svm(n: int, dim: int, rand_bound: float = 10., noisy: bool = False) -> tuple`
  - `...`
- `scaling`
  - `std(data: np.ndarray) -> None`
  - `minmax(data: np.ndarray) -> None`
  - `mean(data: np.ndarray) -> None`
  - `unit(data: np.ndarray) -> None`

## Timeline

- 2019.6.12
  - [x] Linear Regression
  - [x] Logistic Regression
  - [x] Perceptron
  - [x] utils.scaling / batch / cross_validate
- 6.13
  - [x] Support Vector Machine
  - [x] K-Nearest-Neighbor
  - [x] test script
- 6.15
  - [x] Bayes
- 6.16
  - [x] K-Means

- 6.19
  - [ ] Spectral
  - [x] Principle Component Analysis
  - [ ] Decision Tree

## TODO

- å®ç°å…¨éƒ¨ç®—æ³•ä»¥åŠç®—æ³•æµ‹è¯•éƒ¨åˆ†ï¼ˆå½“å‰ç›®æ ‡ï¼‰

- è¡¥å……Ridgeå’ŒLassoç›¸å…³å†…å®¹
- å¯¹äºåˆ†ç±»ç®—æ³•ï¼Œç›®å‰é»˜è®¤å®ç°ä¸ºäºŒåˆ†ç±»ï¼Œéƒ¨åˆ†åˆ†ç±»ç®—æ³•éœ€è¦è¡¥å……å¢åŠ å¤šåˆ†ç±»å®ç°
- å¢åŠ å¤šç§æŸå¤±å‡½æ•°åŠå¯¹åº”æ¢¯åº¦è®¡ç®—æ–¹æ³•å®ç°
- å¢åŠ boostç­‰ensembleæ–¹æ³•å®ç°ï¼ˆåŸºæœ¬ç›®æ ‡ï¼šrandom forestï¼‰
- å¯¹çº¿æ€§æ¨¡å‹ï¼Œå¢åŠ å¤šç§å­¦ä¹ ç‡ä¼˜åŒ–æ–¹å¼ï¼Œå¦‚adagradç­‰

- å¢åŠ ç®—æ³•å¯è§†åŒ–